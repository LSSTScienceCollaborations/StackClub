{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deblending with *Scarlet*\n",
    "<br>Owner(s): **Fred Moolekamp** ([@fred3m](https://github.com/LSSTScienceCollaborations/StackClub/issues/new?body=@fred3m))\n",
    "<br>Level: **Intermediate**\n",
    "<br>Last Verified to Run: **2021-08-24**\n",
    "<br>Verified Stack Release: **w_2021_33**\n",
    "\n",
    "The purpose of this tutorial is to familiarize you with the basics of using `scarlet` to model blended scenes, and how tweaking various objects and parameters affects the resulting model. This tutorial use `scarlet` as a stand-alone package, and does not depend on the LSST DM Science Pipelines. This notebook was developed from an early version of the [scarlet quickstart tutorial](https://pmelchior.github.io/scarlet/0-quickstart.html). A tutorial that is more focused on using `scarlet` in the context of the LSST DM Science Pipelines is available at [Deblending/LsstStackDeblender.ipynb](../Deblending/LsstStackDeblender.ipynb).\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "After working through this tutorial you should be able to: \n",
    "1. Configure and run `scarlet` on a test list of objects;\n",
    "2. Understand its various model assumptions and applied constraints.\n",
    "\n",
    "More documentation is available on in the `scarlet` [docs](https://pmelchior.github.io/scarlet/) and the core concepts of the code are discussed [here](https://pmelchior.github.io/scarlet/1-concepts.html).\n",
    "\n",
    "### Logistics\n",
    "This notebook is intended to be runnable on `lsst-lsp-stable.ncsa.illinois.edu` from a local git clone of https://github.com/LSSTScienceCollaborations/StackClub.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of the Stack are we using?\n",
    "! echo $HOSTNAME\n",
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# don't interpolate the pixels\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import numpy as np\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping\n",
    "\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"scarlet: %s\"%scarlet.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display functions\n",
    "\n",
    "Below are several useful functions used throughout this tutorial to visualize the data and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_psfs(psfs, filters, norm=None):\n",
    "    rows = int(np.ceil(len(psfs)/3))\n",
    "    columns = min(len(psfs), 3)\n",
    "    figsize = (45/columns, rows*5)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = [fig.add_subplot(rows, columns, n+1) for n in range(len(psfs))]\n",
    "    for n, psf in enumerate(psfs):\n",
    "        im = ax[n].imshow(psf, norm=norm)\n",
    "        ax[n].set_title(\"{0}-band PSF\".format(filters[n]))\n",
    "        plt.colorbar(im, ax=ax[n])\n",
    "    plt.show()\n",
    "\n",
    "def display_diff_kernels(psf_blend, diff_kernels):\n",
    "    model = psf_blend.get_model()\n",
    "    for b, component in enumerate(psf_blend.components):\n",
    "        fig = plt.figure(figsize=(15,2.5))\n",
    "        ax = [fig.add_subplot(1,4,n+1) for n in range(4)]\n",
    "        # Display the psf\n",
    "        ax[0].set_title(\"psf\")\n",
    "        _img = ax[0].imshow(psfs[b])\n",
    "        fig.colorbar(_img, ax=ax[0])\n",
    "        # Display the model\n",
    "        ax[1].set_title(\"modeled psf\")\n",
    "        _model = np.ma.array(model[b], mask=model[b]==0)\n",
    "        _img = ax[1].imshow(_model)\n",
    "        fig.colorbar(_img, ax=ax[1])\n",
    "        # Display the difference kernel\n",
    "        ax[2].set_title(\"difference kernel\")\n",
    "        _img = ax[2].imshow(np.ma.array(diff_kernels[b], mask=diff_kernels[b]==0))\n",
    "        fig.colorbar(_img, ax=ax[2])\n",
    "        # Display the residual\n",
    "        ax[3].set_title(\"residual\")\n",
    "        residual = psfs[b]-model[b]\n",
    "        vabs = np.max(np.abs(residual))\n",
    "        _img = ax[3].imshow(residual, vmin=-vabs, vmax=vabs, cmap='seismic')\n",
    "        fig.colorbar(_img, ax=ax[3])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Display the data\n",
    "\n",
    "We download a small file with a blended source from the HSC COSMOS field detected by the LSST pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $HOME/DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "basename = 'hsc_cosmos_35.npz'\n",
    "filename = os.path.expandvars(f'$HOME/DATA/{basename}')\n",
    "if not os.path.exists(filename): \n",
    "    github=\"https://raw.githubusercontent.com/pmelchior/scarlet/master/data/\"\n",
    "    !curl {github}{basename} -o {filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(filename)\n",
    "\n",
    "images = data[\"images\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "peaks = data[\"catalog\"]\n",
    "psfs = data[\"psfs\"]\n",
    "filters = [\"G\", \"R\", \"I\", \"Z\", \"Y\"]\n",
    "\n",
    "# Only a rough estimate of the background is needed\n",
    "# to initialize and resize the sources\n",
    "bg_rms = np.std(images, axis=(1,2))\n",
    "print(\"Background RMS: {0}\".format(bg_rms))\n",
    "\n",
    "# Use Asinh scaling for the images\n",
    "norm = AsinhMapping(minimum=images.min(), stretch=images.max()/20, Q=10)\n",
    "\n",
    "# Convert the image to an RGB image\n",
    "plt.figure(figsize=(10,10))\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Image: {}\".format(basename))\n",
    "for k, src in enumerate(peaks):\n",
    "    plt.text(src[0], src[1], str(k), color=\"cyan\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display PSFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a  look at the `psfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_psfs(psfs, filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model and observation frames\n",
    "\n",
    "A `Frame` in scarlet is the metadata that defines the hyperspectral data cube, including dimensions, WCS (optional), and the PSF (technically optional but recommended). So we need to define a frame for our model and for the `Observation`, which contains the image and variance data for the observations of the scene that we are deblending.  We will create an initial model `Frame` that uses a narrow Gaussian PSF and an `Observation` that consists of multiple bands of an HSC coadded image. See https://pmelchior.github.io/scarlet/1-concepts.html for more on `Frame`s and `Observation`s.\n",
    "\n",
    "In scarlet it is possible to deblend scenes that have observations with different instruments that have different resolutions and/or observations that have not been coadded; however, that is outside the scope of this tutorial and the interested reader is referred to https://pmelchior.github.io/scarlet/tutorials/multiresolution.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image psfs\n",
    "psf = scarlet.ImagePSF(psfs)\n",
    "# We need to provide a reference PSF for the model. We choose a minimal Gaussian PSF as our reference kernel\n",
    "model_psf = scarlet.GaussianPSF(sigma=(0.9,)*len(filters))\n",
    "\n",
    "# Create the initial frame (metadata for the model).\n",
    "frame = scarlet.Frame(images.shape, psf=model_psf, channels=filters)\n",
    "\n",
    "# Create our observation\n",
    "observation = scarlet.Observation(images, psf=psf, channels=filters, weights=weights).match(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Sources\n",
    "\n",
    "Astrophysical objects are modeled in scarlet as a collection of components, where each component has a single SED that is constant over it's morphology (band independent intensity). So a single source might have multiple components, like a bulge and disk, or a single component.\n",
    "\n",
    "The different classes that inherit from `Source` mainly differ in how they are initialized, and otherwise behave similarly during the optimization routine. This section illustrates the differences between different source initialization classes.\n",
    "\n",
    "<span style=\"color:red;font-weight:bold\">WARNING:</span> Scarlet accepts source positions using the numpy/C++ convention of *(y,x)*, which is different than the astropy and LSST stack convention of *(x,y)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we demonstrate the usage of `ExtendedSource`, which initializes each object as a single component with maximum flux at the peak that falls off monotonically and has 180 degree symmetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [scarlet.ExtendedSource(frame, (peak[1], peak[0]), observation) for peak in peaks]\n",
    "\n",
    "# Display the initial guess for each source\n",
    "scarlet.display.show_sources(sources,\n",
    "                             norm=norm,\n",
    "                             observation=observation,\n",
    "                             show_rendered=True,\n",
    "                             show_observed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "1. Experiment with the above code by using `MultiComponentSource`, which models a source as two components (a bulge and a disk) that are each symmetric and montonically decreasing from the peak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deblending a scene\n",
    "\n",
    "The `Blend` class contains the list of sources, the observation(s), and any other configuration parameters necessary to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can fit a model, given a maximum number of iterations and the relative error required for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data until the relative error is <= 1e-3,\n",
    "# for a maximum of 200 iterations\n",
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(200, e_rel = 1e-3)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two options for displaying the scene, using `scarlet.display.show_scene` function. This shows the model along with the observation information and the residuals defined as: `observation.images - model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, norm=norm, \n",
    "                           observation=observation, \n",
    "                           linear=True,\n",
    "                           show_model=True,\n",
    "                           show_rendered=True,\n",
    "                           show_observed=True,\n",
    "                           #add_boxes=True\n",
    "                          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do it by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and calculate the residual\n",
    "model = blend.get_model()\n",
    "model_ = observation.render(model)  # adapt model to observations. \n",
    "residual = images-model_\n",
    "\n",
    "# Create RGB images\n",
    "model_rgb = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "residual_rgb = scarlet.display.img_to_rgb(residual)\n",
    "\n",
    "# Show the data, model, and residual\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "ax[1].imshow(model_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "ax[2].imshow(residual_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "for k,component in enumerate(blend):\n",
    "    y,x = component.center\n",
    "    ax[0].text(x, y, k, color=\"w\")\n",
    "    ax[1].text(x, y, k, color=\"w\")\n",
    "    ax[2].text(x, y, k, color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Experiment by running the above code using different source models (for example `MultiComponentSource` or `PointSource`) to see how initializtion affects the belnding results.\n",
    "\n",
    "2. Change the value of `e_rel` in the above fit and try to understand how it affects the results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
